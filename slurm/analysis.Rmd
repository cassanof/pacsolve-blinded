---
title: "R Notebook"
output:
  pdf_document:
    latex_engine: xelatex
  html_notebook: default
  html_document:
    df_print: paged
  word_document: default
---

# Running on Discovery

I recommend viewing this with a web-based Rstudio server on Discovery:

https://ood.discovery.neu.edu/pun/sys/dashboard/batch_connect/sys/RStudio/session_contexts/new

Press *Ctrl+Enter* to run a chunk.

# Initialization

*You may want to change the directories below.*

```{r setup}
suppressMessages(library(tidyverse))
library(stringr)
library(xtable)
suppressMessages(library(extrafont))
library(fontcm)
```

```{r dirs old}
#knitr::opts_knit$set(root.dir = "/mnt/data/arjun/repos/dependency-runner/slurm")
#data_root <- "/mnt/data/arjun/scratch/npm"
#results_root <- "/mnt/data/arjun/repos/papers/minnpm/paper/figs_and_tables"
#results_tex <- str_c(results_root, "/results.tex")

#write("% These are results from the R Notebook.", results_tex, append=FALSE)
#write("% Run the notebook from top to bottom", results_tex, append=TRUE)
```

```{r dirs}
knitr::opts_knit$set(root.dir = "/work/arjunguha-research-group/pacsolve/slurm") # "/mnt/data/arjun/repos/dependency-runner/slurm"
data_root <- "/scratch/pinckney.d/apr-10-more-combos" # "/mnt/data/arjun/scratch/npm"
results_root <- "/scratch/pinckney.d/apr-10-more-combos-results" # "/mnt/data/arjun/repos/papers/minnpm/paper/figs_and_tables"
results_tex <- str_c(results_root, "/results.tex")

write("% These are results from the R Notebook.", results_tex, append=FALSE)
write("% Run the notebook from top to bottom", results_tex, append=TRUE)
```


# Theme for output

```{r}
mytheme <- function() {
  return(theme_bw() +
           theme(
             text = element_text(family = "CM Roman", size=10),
              panel.grid.major = element_blank(),
             # panel.grid.minor = element_blank(),
             # panel.grid.major = element_line(colour="gray", size=0.1),
             # panel.grid.minor =
             #  element_line(colour="gray", size=0.1, linetype='dotted'),
             axis.ticks = element_line(size=0.05),
             axis.ticks.length=unit("-0.05", "in"),
             axis.text.y = element_text(margin = margin(r = 5)),
             axis.text.x = element_text(hjust=1),
             legend.key = element_rect(colour=NA),
             legend.spacing = unit(0.001, "in"),
             legend.key.size = unit(0.2, "in"),
             legend.title = element_blank(),
             legend.position = c(0.9, .7),
             legend.background = element_blank()))
}

mysave <- function(filename) {
  ggsave(filename, width=3, height=3, units=c("in"))
  # embed_font(filename)
}

```

# Load the data

These are the results from running all experiments in parallel on Discovery.
The timing information is *not* reliable.
```{r}
raw_data <- read_csv(paste(data_root, "/results.csv", sep=""),
  col_types = cols(Status=col_factor(),
                   Project=col_factor(),
                   Rosette=col_logical(),
                   Consistency=col_factor(),
                   DisallowCycles=col_factor(),
                   Minimize=col_factor(),
                   Time=col_double(),
                   NDeps=col_integer()),
  show_col_types = FALSE)
                   
```

We load more data later.

# Manual Verification Step

Check that these are the factors that appear below:

1. *success*: everything worked!
2. *ERESOLVE*: depends on something that isn't in the repository
3. *ETARGET*: requires some other target architecture **verify**. Can also mean depending on something that doesn't exist.
4. *EBADPLATFORM*: requires some other platform (e.g., macOS)
5. *EUNSUPPORTEDPROTOCOL:* a dependency is in a format that NPM does not support
6. *unexpected*: something went wrong on Discovery. See experiment.out
7. *unavailable*: something went wrong and we didn't even capture the result. 
   See experiment.out
8. *unsat*: Z3 failed on us

```{r}
levels(raw_data$Status)
```

```{r}
levels(raw_data$Consistency)
```

```{r}
levels(raw_data$Minimize)
```

```{r}
levels(raw_data$DisallowCycles)
```

Sanity check: there should be 1,000 of each kind of experiment.

```{r}
num_experiments <- raw_data %>% 
  group_by(Rosette,Minimize,Consistency,DisallowCycles) %>%
  summarize(Count = n()) %>%
  ungroup() %>%
  select(Count) %>%
  unique()
stopifnot(nrow(num_experiments) == 1)
stopifnot(num_experiments[1] == 1000)
```

# Failures

How many failures occur for each configuration? *See failures.tex*.

```{r}
# failure_analysis <- raw_data %>% 
#   filter(Status != "success") %>% 
#   group_by(Rosette,Minimize,Consistency)

failure_analysis <- raw_data %>% 
  filter(Status != "success") %>%
  group_by(Rosette,Minimize,Consistency,DisallowCycles) %>%
  summarise(Unsat = sum(Status == "unsat"),
            Timeout = sum(Status == "unavailable" | Status == "timeout"),
            Other = sum(Status != "unsat" & Status != "unavailable" & Status != "timeout")) %>%
  ungroup() %>%
  mutate(Solver = if_else(Rosette, "MinNPM", "NPM")) %>%
  rename(Minimization = Minimize) %>%
  select(-Rosette) %>%
  relocate(Solver,Consistency,DisallowCycles,Minimization,Unsat,Timeout,Other)
print(xtable(as.data.frame(failure_analysis), type="latex"), include.rownames=FALSE, file="failures.tex")
knitr::kable(failure_analysis)
```

Projects that produced a Z3 unsat with Pip-consistency, but succeeded with
Npm-consistency:

```{r}
requires_multiple_versions <- raw_data %>% 
  filter(Rosette == TRUE &
           Consistency == "pip" &
           Minimize == "min_oldness,min_num_deps" &
           Status != "success") %>%
  select(Project) %>%
  inner_join(raw_data %>%
               filter(Rosette == TRUE &
                        Consistency == "npm" &
                        Minimize == "min_oldness,min_num_deps" &
                        Status == "success") %>%
               select(Project))
requires_multiple_versions
```
```{r}
fraction_require_npm_consistency <- nrow(requires_multiple_versions) /
  nrow(raw_data %>%  filter(Rosette == FALSE))
write(
  str_c("\\newcommand{\\dataFractionPIPUnsupported}{", 
        round(fraction_require_npm_consistency * 100),
        "\\%}\n"),
  results_tex, append=TRUE)
```

Projects that failed in with MinNPM in NPM mode, but succeeded with NPM. The
Status column shows the status with MinNPM. The status *unavailable* means
a timeout, whereas *unexpected* likely means some kind of Z3 / Rosette crash.

```{r}
minnpm_succeeds_npm_fails <- raw_data %>% 
  filter(Rosette == TRUE &
           Consistency == "npm" &
           Minimize == "min_oldness,min_num_deps" &
           Status != "success") %>%
  select(Project, Status) %>%
  inner_join(raw_data %>%
               filter(Rosette == FALSE &
                        Status == "success") %>%
               select(Project))
knitr::kable(minnpm_succeeds_npm_fails)
```

```{r}
nrow(minnpm_succeeds_npm_fails)

```

Projects that succeeded with MinNPM in NPM mode, but failed with NPM. The
Status column shows the status with NPM. I've more carefully parsed the
error codes from NPM. It is surprising, and nice, that there are nearly as
many failures in this direction.

```{r}
raw_data %>% 
  filter(Rosette == TRUE &
           Consistency == "npm" &
           Minimize == "min_oldness,min_num_deps" &
           Status == "success") %>%
  select(Project, NDeps) %>%
  inner_join(raw_data %>%
               filter(Rosette == FALSE &
                        Status != "success") %>%
               select(Project, Status))

```



#  The Need for Tree-Solving

NPM uses a tree-solver because its easy to resolve conflicts. But, how many conflicts do you see with MinNPM in PIP mode?

<span style="color:red">TODO: Need to process output further to distinguish these errors.</span>

# Can MinNPM produce fewer dependencies than NPM?

For each project, the number of dependencies with vanilla NPM, and with MinNPM
configured to minimize #deps and oldness, in that order.
```{r}
min_dep_analysis <- bind_rows(raw_data %>% 
            filter(Rosette == FALSE & Status == "success") %>% 
            select(Project,NDeps) %>% 
            mutate(Solver="NPM"),
          raw_data %>% 
            filter(Rosette == TRUE & Status == "success" & Consistency == "npm" &
                   Minimize == "min_num_deps,min_oldness") %>%
            select(Project, NDeps) %>%
            mutate(Solver="MinDeps")) %>%
  pivot_wider(values_from=NDeps, names_from=Solver) %>%
  mutate(Delta = NPM - MinDeps) %>%
  mutate(Shrinkage = MinDeps / NPM) %>%
  na.omit()
min_dep_analysis
```

These are cases where MinNPM produces significantly fewer dependences than
NPM. We may want to dig into them further to explain why:
```{r}
min_dep_analysis %>% 
  arrange(desc(Delta)) %>%
  filter(Delta > 25) %>%
  knitr::kable()
```

These are potentially bad cases, where MinNPM produces more dependencies than
NPM:

```{r}
min_dep_analysis %>% arrange(Delta) %>% filter(Delta < 0)
```

*WARNING: This filters out the bogus result above.*

```{r}
min_dep_analysis %>% 
  select(Shrinkage) %>%
  filter(Shrinkage <= 1.0) %>%
  ggplot(aes(Shrinkage)) +
  stat_ecdf() +
  ylab("Percentange of packages") +
  xlab("Fraction of dependencies") +
  mytheme()
mysave("shrinkage.pdf")
```

*What fraction of packages can we shrink? This goes in the paper.*

```{r}
fraction_shrinking <- nrow(
  min_dep_analysis %>% filter(Shrinkage < 1)) / nrow(min_dep_analysis)
write(
  str_c("\\newcommand{\\dataFractionShrinking}{", 
        round(fraction_shrinking * 100),
        "\\%}\n"),
  results_tex, append=TRUE)
fraction_shrinking
```

  
# How Old Are Dependencies?

I ran:

$ python3 all_oldness.py /scratch/a.guha/minnpm-exp/vanilla > oldness_vanilla.csv
$ python3 all_oldness.py /scratch/a.guha/minnpm-exp/rosette/npm/min_oldness,min_numâ”‚
_deps > oldness_npm_oldness_deps.csv

Raw data
```{r}
oldness_data <- bind_rows(
  read_csv(paste(data_root, "/oldness_vanilla.csv", sep=""),
    col_types = cols(Package=col_factor(),
                     Oldness=col_double()),
    show_col_types = FALSE) %>%
    mutate(Solver = "NPM"),
  read_csv(paste(data_root, "/oldness_npm_oldness_deps.csv", sep=""),
    col_types = cols(Package=col_factor(),
                     Oldness=col_double()),
    show_col_types = FALSE) %>%
    mutate(Solver = "MinNPM"))

```

```{r}
oldness_by_pkg <- oldness_data %>% 
  pivot_wider(values_from = Oldness, names_from=Solver)
better_oldness <- nrow(oldness_by_pkg  %>% filter(MinNPM < NPM)) /
  nrow(oldness_by_pkg)
write(
  str_c("\\newcommand{\\dataFractionNewer}{", 
        round(better_oldness * 100),
        "\\%}\n"),
  results_tex, append=TRUE)
```


```{r}
oldness_data %>%
  filter(!is.nan(Oldness)) %>%
  pivot_wider(names_from=Solver, values_from=Oldness) %>%
  mutate(Delta = NPM - MinNPM) %>%
  mutate(Ratio = MinNPM / NPM) %>%
  filter(Delta > 0)
```

```{r}
oldness_data %>%
  filter(!is.nan(Oldness)) %>%
  pivot_wider(names_from=Solver, values_from=Oldness) %>%
  ggplot(aes(x=NPM,y=MinNPM)) + 
  geom_point(shape=4, size=1.5) + 
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), size=0.02, color="red") +
  xlab("Oldness with NPM") +
  ylab("Oldness with MinNPM") +
  mytheme()

mysave("oldness_scatterplot.pdf")

```

# Performance Analysis

```{r}
slowdowns <- read_csv(paste(data_root,"/vanilla/performance.csv",sep=""),
         col_types = cols(Package = col_factor(), Time = col_double()),
         show_col_types = FALSE) %>%
  group_by(Package) %>%
  summarise(NPM = mean(Time)) %>%
  ungroup() %>%
  inner_join(
    read_csv(paste(data_root,"/rosette/npm/min_oldness,min_num_deps/performance.csv",sep=""),
             col_types = cols(Package = col_factor(), Time = col_double()),
             show_col_types = FALSE) %>%
        group_by(Package) %>%
      summarise(MinNPM = mean(Time)) %>%
      ungroup()) %>%
  mutate(Slowdown = MinNPM - NPM) %>%
  select(Package, Slowdown)

slowdowns %>% ggplot(aes(x=Slowdown)) + 
  stat_ecdf() +
  xlab("Additional time taken with MinNPM (s)") +
  ylab("Percentage of packages") +
  mytheme()

mysave("slowdown_ecdf.pdf")
```

Reported in paper:

```{r}
write(
  str_c("\\newcommand{\\dataMeanSlowdown}{", 
        round(mean(na.omit(slowdowns$Slowdown)), digits = 1),
        "s}\n"),
  results_tex, append=TRUE)
write(
  str_c("\\newcommand{\\dataMaxSlowdown}{", 
        round(max(na.omit(slowdowns$Slowdown)), digits = 1),
        "s}\n"),
  results_tex, append=TRUE)
```

